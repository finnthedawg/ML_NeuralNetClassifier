{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn #neural net\n",
    "import torch.nn.functional as F #Functions such as relu\n",
    "import torch.optim as optim #Parameter optimization functions\n",
    "import numpy as np\n",
    "from scipy.io import loadmat #Loading data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ANN(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        #Define the network\n",
    "        super(ANN, self).__init__()\n",
    "        self.fc1 = nn.Linear(400, 25)\n",
    "        self.fc2 = nn.Linear(25,10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return(x)\n",
    "    def loadWeight(self, weights):\n",
    "        \n",
    "        fc1 = torch.from_numpy(weights[\"Theta1\"][:,:-1]).float()\n",
    "        fc1Bias = torch.from_numpy(weights[\"Theta1\"][:,0]).float()\n",
    "        fc2 = torch.from_numpy(weights[\"Theta2\"][:,:-1]).float()\n",
    "        fc2Bias = torch.from_numpy(weights[\"Theta2\"][:,0]).float()\n",
    "        \n",
    "        print(fc1.shape)\n",
    "        print(fc1Bias)\n",
    "        print(fc2Bias)\n",
    "        \n",
    "        param = list(self.parameters())\n",
    "        param[0].data.sub_(fc1)\n",
    "        param[1].data.sub_(fc1Bias)\n",
    "        param[2].data.sub_(fc2)\n",
    "        param[3].data.sub_(fc2Bias)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadData(name):\n",
    "    return(loadmat(name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape:  (5000, 400)\n",
      "Output shape:  (5000, 1)\n"
     ]
    }
   ],
   "source": [
    "data = loadData(\"ex3data1.mat\")\n",
    "print(\"Input shape: \", data[\"X\"].shape)\n",
    "print(\"Output shape: \", data[\"y\"].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialize the neural net\n",
    "classifier = ANN()\n",
    "#Create the optim\n",
    "optimizer = optim.SGD(classifier.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(403.4504, grad_fn=<MseLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "#Define the loss function.\n",
    "\n",
    "#Train with SGD for each image. \n",
    "optimizer.zero_grad()   # zero the gradient buffers\n",
    "features = torch.from_numpy(data[\"X\"][0]).float()\n",
    "target = torch.zeros((10))\n",
    "target[data[\"y\"][0]-1] = 1.0\n",
    "output = classifier(features)\n",
    "loss = nn.MSELoss()(output, target)\n",
    "print(loss)\n",
    "loss.backward()\n",
    "optimizer.step()    # Does the update\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Update the weights."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy of loaded weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([25, 400])\n",
      "tensor([-0.0226, -0.0984,  0.1162, -0.2397, -0.7316, -0.5979,  0.1546, -0.0337,\n",
      "        -0.4107,  0.0235,  0.2477,  0.2653,  0.0943,  0.2022, -0.2030,  0.1046,\n",
      "         0.1489, -0.0379, -0.3320, -0.2977, -0.4842, -0.3898, -0.1832, -0.7021,\n",
      "        -0.3509])\n",
      "tensor([-0.7610, -0.6179, -0.6893, -0.6783, -0.5966, -0.8779, -0.5275, -0.7490,\n",
      "        -0.6665, -0.4609])\n"
     ]
    }
   ],
   "source": [
    "#Load some weights\n",
    "weights = loadData(\"ex3weights.mat\")\n",
    "classifier.loadWeight(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
